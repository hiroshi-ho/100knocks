{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトカー\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#http://www.cl.ecei.tohoku.ac.jp/nlp100/\n",
    "#001\n",
    "s01 = list(\"パタトクカシー\")\n",
    "print(s01[0] + s01[2] + s01[4] + s01[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "# 002\n",
    "s1l = list(\"パトカー\")\n",
    "s2l = list(\"タクシー\")\n",
    "s3 = ''\n",
    "for i in range(len(s1l)):\n",
    "    s3 = s3 + s1l[i] + s2l[i]\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'He', 'Lied', 'Because', 'Boron', 'Could', 'Not', 'Oxidize', 'Fluorine', '.', 'New', 'Nations', 'Might', 'Also', 'Sign', 'Peace', 'Security', 'Clause', '.', 'Arthur', 'King', 'Can', '.']\n",
      "23\n",
      "{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10, 'Na': 11, 'Mi': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20}\n"
     ]
    }
   ],
   "source": [
    "#003\n",
    "import nltk as nl\n",
    "str04 = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "j = nl.word_tokenize(str04)\n",
    "str04dict = {}\n",
    "print(j)\n",
    "print(len(j))\n",
    "while '.' in j:\n",
    "    j.remove('.')\n",
    "\n",
    "for i in range(len(j)):\n",
    "    if i + 1 in [1, 5, 6, 7, 8, 9, 15, 16, 19] :\n",
    "        jk = str(j[i])\n",
    "        jj = list(jk)\n",
    "        str04dict.update({jj[0]:(i + 1)})\n",
    "    else:\n",
    "        jk = str(j[i])\n",
    "        jj = list(jk)\n",
    "        str04dict.update({(jj[0]+jj[1]):i + 1})\n",
    "        \n",
    "print(str04dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pa', 'ar', 'ra', 'ap', 'pa', 'ar', 'ra', 'ap', 'pa', 'ar', 'ra', 'ad', 'di', 'is', 'se'] ['pa', 'ar', 'ra', 'ad', 'di', 'is', 'se']\n",
      "{'ra', 'ad', 'di', 'ap', 'is', 'se', 'pa', 'ar'}\n",
      "{'ap'}\n",
      "{'ap'}\n",
      "{'ra', 'ad', 'di', 'is', 'se', 'pa', 'ar'}\n"
     ]
    }
   ],
   "source": [
    "#006\n",
    "import nltk\n",
    "\n",
    "def func005(lll, n):\n",
    "    sl = list(lll)\n",
    "    sw = []\n",
    "    if ' ' in lll:\n",
    "        sw =  nltk.word_tokenize(lll)\n",
    "    while '.'in sw:\n",
    "        sw.remove('.')\n",
    "    nl = []\n",
    "    nw = []\n",
    "    for i in range(len(sl) - n + 1):\n",
    "        ppp = []\n",
    "        for j in range(n):\n",
    "            ppp.append(sl[i + j])\n",
    "        nl.append(ppp)\n",
    "        \n",
    "    for i in range(len(sw) - n + 1):\n",
    "        qqq = []\n",
    "        for j in range(n):\n",
    "            qqq.append(sw[i + j])\n",
    "        nw.append(qqq)\n",
    "    return nl , nw\n",
    "\n",
    "X , nwparapara = func005('paraparaparadise',2)\n",
    "Y, nwpara = func005('paradise',2)\n",
    "\n",
    "XX, YY = [] , []\n",
    "for i in X:\n",
    "    j = i[0] + i[1]\n",
    "    XX.append(j)\n",
    "for i in Y:\n",
    "    j = i[0] + i[1]\n",
    "    YY.append(j)\n",
    "    \n",
    "print(XX,YY)\n",
    "\n",
    "sX = set(XX)\n",
    "sY = set(YY)\n",
    "\n",
    "print(sX | sY)\n",
    "print(sX ^ sY)\n",
    "print(sX - sY)\n",
    "print(sX and sY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', ' '], [' ', 'a'], ['a', 'm'], ['m', ' '], [' ', 'a'], ['a', 'n'], ['n', ' '], [' ', 'N'], ['N', 'L'], ['L', 'P'], ['P', 'e'], ['e', 'r']] [['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n"
     ]
    }
   ],
   "source": [
    "#005\n",
    "import nltk\n",
    "def func005(lll, n):\n",
    "    sl = list(lll)\n",
    "    sw = []\n",
    "    if ' ' in lll:\n",
    "        sw =  nltk.word_tokenize(lll)\n",
    "    while '.'in sw:\n",
    "        sw.remove('.')\n",
    "    nl = []\n",
    "    nw = []\n",
    "    for i in range(len(sl) - n + 1):\n",
    "        ppp = []\n",
    "        for j in range(n):\n",
    "            ppp.append(sl[i + j])\n",
    "        nl.append(ppp)\n",
    "        \n",
    "    for i in range(len(sw) - n + 1):\n",
    "        qqq = []\n",
    "        for j in range(n):\n",
    "            qqq.append(sw[i + j])\n",
    "        nw.append(qqq)\n",
    "    print(nl,nw)\n",
    "    return nl , nw\n",
    "\n",
    "aa05, bb05 = func005(\"I am an NLPer\",2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12時の気温は22.4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#007\n",
    "def template(x,y,z):\n",
    "    return (str(x) + '時の'+ str(y) +'は'+ str(z))\n",
    "    \n",
    "template(12,\"気温\",22.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "[97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122]\n"
     ]
    }
   ],
   "source": [
    "#008 botsu\n",
    "lis008 = list('abcdefghijklmnopqrstuvwxyz')\n",
    "s = list(str(input()))\n",
    "\n",
    "for i in range(len(s)):\n",
    "    if s[i] not in lis008:\n",
    "        None\n",
    "    else:\n",
    "        p = s[i]\n",
    "        q = 219 - ord(p)\n",
    "        s[i] = str(q)\n",
    "ss= ''        \n",
    "for j in s:\n",
    "    ss = ss + j\n",
    "print(ss)\n",
    "\n",
    "lis0088 = []\n",
    "for i in lis008:\n",
    "    lis0088.append(ord(i))\n",
    "    \n",
    "\n",
    "print(lis0088)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I zn z nzm\n",
      "I am a man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am a man'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#008\n",
    "lis008 = list('abcdefghijklmnopqrstuvwxyz')\n",
    "\n",
    "import nltk\n",
    "def cipher(zzz):\n",
    "    f = ''\n",
    "    p = nltk.word_tokenize(zzz)\n",
    "    for i in range(len(p)):\n",
    "        q = list(str(p[i]))\n",
    "        for j in range(len(q)):\n",
    "            if q[j] in lis008:\n",
    "                f = f + chr(219-ord(q[j]))\n",
    "            else:\n",
    "                f = f + q[j]\n",
    "        if i != len(p) -1:\n",
    "            f = f + ' '\n",
    "    print(f)\n",
    "    return f\n",
    "\n",
    "cipher('I am a man')\n",
    "cipher('I zn z nzm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'cloud', \"n't\", 'bvielee', 'that', 'I', 'could', 'aaucltly', 'utsaednnrd', 'what', 'I', 'was', 'redanig', ':', 'the', 'pnaeenohml', 'poewr', 'of', 'the', 'huamn', 'mind', '.']\n"
     ]
    }
   ],
   "source": [
    "#009\n",
    "import nltk\n",
    "import random\n",
    "s009 = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "s009n = nltk.word_tokenize(s009)\n",
    "\n",
    "s009new = []\n",
    "\n",
    "for i in range(len(s009n)):\n",
    "    if len(list(s009n[i])) < 5:\n",
    "        s009new.append(s009n[i])\n",
    "    else:\n",
    "        q = list(s009n[i])\n",
    "        r = q[0]\n",
    "        s = q[-1]\n",
    "        t = q\n",
    "        t.remove(t[0])\n",
    "        t.remove(t[-1])\n",
    "        random.shuffle(t)\n",
    "        u = ''\n",
    "        u = u + r\n",
    "        for i in range(len(t)):\n",
    "            u = u + t[i]\n",
    "        u = u + s\n",
    "        s009new.append(u)\n",
    "\n",
    "print(s009new)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n➜  100knock wc hightemp.txt\\n 24  96 813 hightemp.txt\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#010\n",
    "num_lines = sum(1 for line in open('hightemp.txt'))\n",
    "print(num_lines)\n",
    "\n",
    "'''\n",
    "➜  100knock wc hightemp.txt\n",
    " 24  96 813 hightemp.txt\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "高知県\t江川崎\t41\t2013-08-12\n",
      "\n",
      "埼玉県\t熊谷\t40.9\t2007-08-16\n",
      "\n",
      "岐阜県\t多治見\t40.9\t2007-08-16\n",
      "\n",
      "山形県\t山形\t40.8\t1933-07-25\n",
      "\n",
      "山梨県\t甲府\t40.7\t2013-08-10\n",
      "\n",
      "和歌山県\tかつらぎ\t40.6\t1994-08-08\n",
      "\n",
      "静岡県\t天竜\t40.6\t1994-08-04\n",
      "\n",
      "山梨県\t勝沼\t40.5\t2013-08-10\n",
      "\n",
      "埼玉県\t越谷\t40.4\t2007-08-16\n",
      "\n",
      "群馬県\t館林\t40.3\t2007-08-16\n",
      "\n",
      "群馬県\t上里見\t40.3\t1998-07-04\n",
      "\n",
      "愛知県\t愛西\t40.3\t1994-08-05\n",
      "\n",
      "千葉県\t牛久\t40.2\t2004-07-20\n",
      "\n",
      "静岡県\t佐久間\t40.2\t2001-07-24\n",
      "\n",
      "愛媛県\t宇和島\t40.2\t1927-07-22\n",
      "\n",
      "山形県\t酒田\t40.1\t1978-08-03\n",
      "\n",
      "岐阜県\t美濃\t40\t2007-08-16\n",
      "\n",
      "群馬県\t前橋\t40\t2001-07-24\n",
      "\n",
      "千葉県\t茂原\t39.9\t2013-08-11\n",
      "\n",
      "埼玉県\t鳩山\t39.9\t1997-07-05\n",
      "\n",
      "大阪府\t豊中\t39.9\t1994-08-08\n",
      "\n",
      "山梨県\t大月\t39.9\t1990-07-19\n",
      "\n",
      "山形県\t鶴岡\t39.9\t1978-08-03\n",
      "\n",
      "愛知県\t名古屋\t39.9\t1942-08-02\n",
      "\n",
      "<_io.TextIOWrapper name='hightemp.txt' mode='r' encoding='utf-8'>\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "#010\n",
    "\n",
    "line_number = 0\n",
    "with open('hightemp.txt',encoding = 'utf-8') as a_file:\n",
    "    for a_line in a_file:\n",
    "        line_number += 1\n",
    "        print(a_line)\n",
    "    print(a_file)\n",
    "    print(line_number)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "高知県 江川崎 41 2013-08-12\n",
      "埼玉県 熊谷 40.9 2007-08-16\n",
      "岐阜県 多治見 40.9 2007-08-16\n",
      "山形県 山形 40.8 1933-07-25\n",
      "山梨県 甲府 40.7 2013-08-10\n",
      "和歌山県 かつらぎ 40.6 1994-08-08\n",
      "静岡県 天竜 40.6 1994-08-04\n",
      "山梨県 勝沼 40.5 2013-08-10\n",
      "埼玉県 越谷 40.4 2007-08-16\n",
      "群馬県 館林 40.3 2007-08-16\n",
      "群馬県 上里見 40.3 1998-07-04\n",
      "愛知県 愛西 40.3 1994-08-05\n",
      "千葉県 牛久 40.2 2004-07-20\n",
      "静岡県 佐久間 40.2 2001-07-24\n",
      "愛媛県 宇和島 40.2 1927-07-22\n",
      "山形県 酒田 40.1 1978-08-03\n",
      "岐阜県 美濃 40 2007-08-16\n",
      "群馬県 前橋 40 2001-07-24\n",
      "千葉県 茂原 39.9 2013-08-11\n",
      "埼玉県 鳩山 39.9 1997-07-05\n",
      "大阪府 豊中 39.9 1994-08-08\n",
      "山梨県 大月 39.9 1990-07-19\n",
      "山形県 鶴岡 39.9 1978-08-03\n",
      "愛知県 名古屋 39.9 1942-08-02\n",
      "高知県 江川崎 41 2013-08-12\n",
      "埼玉県 熊谷 40.9 2007-08-16\n",
      "岐阜県 多治見 40.9 2007-08-16\n",
      "山形県 山形 40.8 1933-07-25\n",
      "山梨県 甲府 40.7 2013-08-10\n",
      "和歌山県 かつらぎ 40.6 1994-08-08\n",
      "静岡県 天竜 40.6 1994-08-04\n",
      "山梨県 勝沼 40.5 2013-08-10\n",
      "埼玉県 越谷 40.4 2007-08-16\n",
      "群馬県 館林 40.3 2007-08-16\n",
      "群馬県 上里見 40.3 1998-07-04\n",
      "愛知県 愛西 40.3 1994-08-05\n",
      "千葉県 牛久 40.2 2004-07-20\n",
      "静岡県 佐久間 40.2 2001-07-24\n",
      "愛媛県 宇和島 40.2 1927-07-22\n",
      "山形県 酒田 40.1 1978-08-03\n",
      "岐阜県 美濃 40 2007-08-16\n",
      "群馬県 前橋 40 2001-07-24\n",
      "千葉県 茂原 39.9 2013-08-11\n",
      "埼玉県 鳩山 39.9 1997-07-05\n",
      "大阪府 豊中 39.9 1994-08-08\n",
      "山梨県 大月 39.9 1990-07-19\n",
      "山形県 鶴岡 39.9 1978-08-03\n",
      "愛知県 名古屋 39.9 1942-08-02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#011\n",
    "with open('hightemp.txt',encoding = 'utf-8') as a_file:\n",
    "    with open('hightemp_011_4',mode = 'w', encoding='utf-8') as new_file:\n",
    "        new_file.write(\"\")\n",
    "        \n",
    "    for line in a_file:\n",
    "        line2 = line.split(\"\\t\")\n",
    "        #print(line2)\n",
    "        str1 = \" \".join(line2)\n",
    "        #print(str1)\n",
    "        #print('#this is one line')\n",
    "        \n",
    "        with open('hightemp_011_4.txt', mode='a', encoding = 'utf-8') as new_file:\n",
    "            new_file.write(str1)\n",
    "            \n",
    "with open('hightemp_011_4.txt', encoding= 'utf-8') as a_file:\n",
    "    print(a_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "高知県 江川崎 41 2013-08-12\n",
      "埼玉県 熊谷 40.9 2007-08-16\n",
      "岐阜県 多治見 40.9 2007-08-16\n",
      "山形県 山形 40.8 1933-07-25\n",
      "山梨県 甲府 40.7 2013-08-10\n",
      "和歌山県 かつらぎ 40.6 1994-08-08\n",
      "静岡県 天竜 40.6 1994-08-04\n",
      "山梨県 勝沼 40.5 2013-08-10\n",
      "埼玉県 越谷 40.4 2007-08-16\n",
      "群馬県 館林 40.3 2007-08-16\n",
      "群馬県 上里見 40.3 1998-07-04\n",
      "愛知県 愛西 40.3 1994-08-05\n",
      "千葉県 牛久 40.2 2004-07-20\n",
      "静岡県 佐久間 40.2 2001-07-24\n",
      "愛媛県 宇和島 40.2 1927-07-22\n",
      "山形県 酒田 40.1 1978-08-03\n",
      "岐阜県 美濃 40 2007-08-16\n",
      "群馬県 前橋 40 2001-07-24\n",
      "千葉県 茂原 39.9 2013-08-11\n",
      "埼玉県 鳩山 39.9 1997-07-05\n",
      "大阪府 豊中 39.9 1994-08-08\n",
      "山梨県 大月 39.9 1990-07-19\n",
      "山形県 鶴岡 39.9 1978-08-03\n",
      "愛知県 名古屋 39.9 1942-08-02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#011\n",
    "\n",
    "with open('hightemp_011_5.txt',mode = 'a', encoding='utf-8') as new_file:\n",
    "        new_file.write(\"\")\n",
    "\n",
    "with open('hightemp.txt',encoding = 'utf-8') as a_file:\n",
    "    with open('hightemp_011_5.txt',mode = 'w', encoding='utf-8') as new_file:\n",
    "        new_file.write(\"\")\n",
    "        \n",
    "        for line in a_file:\n",
    "            line2 = line.split(\"\\t\")\n",
    "            str1 = \" \".join(line2)\n",
    "            new_file.write(str1)\n",
    "            \n",
    "with open('hightemp_011_5.txt', mode ='r',encoding= 'utf-8') as a_file:\n",
    "    print(a_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<BOS>', '高知県', '江川崎', '41', '2013-08-12', '<EOS>']\n",
      "['<BOS>', '埼玉県', '熊谷', '40.9', '2007-08-16', '<EOS>']\n",
      "['<BOS>', '岐阜県', '多治見', '40.9', '2007-08-16', '<EOS>']\n",
      "['<BOS>', '山形県', '山形', '40.8', '1933-07-25', '<EOS>']\n",
      "['<BOS>', '山梨県', '甲府', '40.7', '2013-08-10', '<EOS>']\n",
      "['<BOS>', '和歌山県', 'かつらぎ', '40.6', '1994-08-08', '<EOS>']\n",
      "['<BOS>', '静岡県', '天竜', '40.6', '1994-08-04', '<EOS>']\n",
      "['<BOS>', '山梨県', '勝沼', '40.5', '2013-08-10', '<EOS>']\n",
      "['<BOS>', '埼玉県', '越谷', '40.4', '2007-08-16', '<EOS>']\n",
      "['<BOS>', '群馬県', '館林', '40.3', '2007-08-16', '<EOS>']\n",
      "['<BOS>', '群馬県', '上里見', '40.3', '1998-07-04', '<EOS>']\n",
      "['<BOS>', '愛知県', '愛西', '40.3', '1994-08-05', '<EOS>']\n",
      "['<BOS>', '千葉県', '牛久', '40.2', '2004-07-20', '<EOS>']\n",
      "['<BOS>', '静岡県', '佐久間', '40.2', '2001-07-24', '<EOS>']\n",
      "['<BOS>', '愛媛県', '宇和島', '40.2', '1927-07-22', '<EOS>']\n",
      "['<BOS>', '山形県', '酒田', '40.1', '1978-08-03', '<EOS>']\n",
      "['<BOS>', '岐阜県', '美濃', '40', '2007-08-16', '<EOS>']\n",
      "['<BOS>', '群馬県', '前橋', '40', '2001-07-24', '<EOS>']\n",
      "['<BOS>', '千葉県', '茂原', '39.9', '2013-08-11', '<EOS>']\n",
      "['<BOS>', '埼玉県', '鳩山', '39.9', '1997-07-05', '<EOS>']\n",
      "['<BOS>', '大阪府', '豊中', '39.9', '1994-08-08', '<EOS>']\n",
      "['<BOS>', '山梨県', '大月', '39.9', '1990-07-19', '<EOS>']\n",
      "['<BOS>', '山形県', '鶴岡', '39.9', '1978-08-03', '<EOS>']\n",
      "['<BOS>', '愛知県', '名古屋', '39.9', '1942-08-02', '<EOS>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#011\n",
    "\n",
    "with open('hightemp_011_5.txt',mode = 'a', encoding='utf-8') as new_file:\n",
    "        new_file.write(\"\")\n",
    "\n",
    "with open('hightemp.txt',encoding = 'utf-8') as a_file:\n",
    "    with open('hightemp_011_5.txt',mode = 'w', encoding='utf-8') as new_file:\n",
    "        new_file.write(\"\")\n",
    "        \n",
    "        for line in a_file:\n",
    "            line3 = line.strip('\\n')\n",
    "            line2 = line3.split(\"\\t\")\n",
    "            \n",
    "            onelist = ['<BOS>']\n",
    "            for _ in line2:\n",
    "                onelist.append(_)\n",
    "            onelist.append('<EOS>')\n",
    "            \n",
    "            print(onelist)\n",
    "\n",
    "            \n",
    "with open('hightemp_011_5.txt', mode ='r',encoding= 'utf-8') as a_file:\n",
    "    print(a_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['高知県', '江川崎', '41', '2013-08-12\\n']\n",
      "['埼玉県', '熊谷', '40.9', '2007-08-16\\n']\n",
      "['岐阜県', '多治見', '40.9', '2007-08-16\\n']\n",
      "['山形県', '山形', '40.8', '1933-07-25\\n']\n",
      "['山梨県', '甲府', '40.7', '2013-08-10\\n']\n",
      "['和歌山県', 'かつらぎ', '40.6', '1994-08-08\\n']\n",
      "['静岡県', '天竜', '40.6', '1994-08-04\\n']\n",
      "['山梨県', '勝沼', '40.5', '2013-08-10\\n']\n",
      "['埼玉県', '越谷', '40.4', '2007-08-16\\n']\n",
      "['群馬県', '館林', '40.3', '2007-08-16\\n']\n",
      "['群馬県', '上里見', '40.3', '1998-07-04\\n']\n",
      "['愛知県', '愛西', '40.3', '1994-08-05\\n']\n",
      "['千葉県', '牛久', '40.2', '2004-07-20\\n']\n",
      "['静岡県', '佐久間', '40.2', '2001-07-24\\n']\n",
      "['愛媛県', '宇和島', '40.2', '1927-07-22\\n']\n",
      "['山形県', '酒田', '40.1', '1978-08-03\\n']\n",
      "['岐阜県', '美濃', '40', '2007-08-16\\n']\n",
      "['群馬県', '前橋', '40', '2001-07-24\\n']\n",
      "['千葉県', '茂原', '39.9', '2013-08-11\\n']\n",
      "['埼玉県', '鳩山', '39.9', '1997-07-05\\n']\n",
      "['大阪府', '豊中', '39.9', '1994-08-08\\n']\n",
      "['山梨県', '大月', '39.9', '1990-07-19\\n']\n",
      "['山形県', '鶴岡', '39.9', '1978-08-03\\n']\n",
      "['愛知県', '名古屋', '39.9', '1942-08-02\\n']\n",
      "\n",
      " ['高知県', '埼玉県', '岐阜県', '山形県', '山梨県', '和歌山県', '静岡県', '山梨県', '埼玉県', '群馬県', '群馬県', '愛知県', '千葉県', '静岡県', '愛媛県', '山形県', '岐阜県', '群馬県', '千葉県', '埼玉県', '大阪府', '山梨県', '山形県', '愛知県'] \n",
      " ['江川崎', '熊谷', '多治見', '山形', '甲府', 'かつらぎ', '天竜', '勝沼', '越谷', '館林', '上里見', '愛西', '牛久', '佐久間', '宇和島', '酒田', '美濃', '前橋', '茂原', '鳩山', '豊中', '大月', '鶴岡', '名古屋']\n",
      "\n",
      "高知県\t江川崎\n",
      "埼玉県\t熊谷\n",
      "岐阜県\t多治見\n",
      "山形県\t山形\n",
      "山梨県\t甲府\n",
      "和歌山県\tかつらぎ\n",
      "静岡県\t天竜\n",
      "山梨県\t勝沼\n",
      "埼玉県\t越谷\n",
      "群馬県\t館林\n",
      "群馬県\t上里見\n",
      "愛知県\t愛西\n",
      "千葉県\t牛久\n",
      "静岡県\t佐久間\n",
      "愛媛県\t宇和島\n",
      "山形県\t酒田\n",
      "岐阜県\t美濃\n",
      "群馬県\t前橋\n",
      "千葉県\t茂原\n",
      "埼玉県\t鳩山\n",
      "大阪府\t豊中\n",
      "山梨県\t大月\n",
      "山形県\t鶴岡\n",
      "愛知県\t名古屋\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#012-013\n",
    "with open('hightemp.txt',encoding = 'utf-8') as a_file:\n",
    "    \n",
    "    col1_list = []\n",
    "    col2_list = []\n",
    "    \n",
    "    with open('col1.txt',mode = 'w', encoding = 'utf-8') as new_file:\n",
    "        new_file.write(\"\")\n",
    "        \n",
    "    with open('col2.txt',mode = 'w', encoding = 'utf-8') as new_file:\n",
    "        new_file.write(\"\")\n",
    "\n",
    "    with open('col1plus2.txt',mode = 'w', encoding = 'utf-8') as new_file:\n",
    "        new_file.write(\"\")  \n",
    "        \n",
    "    for line in a_file:\n",
    "        line2 = list(line.split(\"\\t\"))\n",
    "        print(line2)\n",
    "        col1_list.append(line2[0])\n",
    "        col2_list.append(line2[1])\n",
    "     \n",
    "    print('\\n',col1_list,'\\n',col2_list)\n",
    "\n",
    "    for i in range(24):\n",
    "        onestr = str(col1_list[i]) + '\\t' + str(col2_list[i]) + '\\n'\n",
    "        with open('col1plus2.txt', mode = 'a', encoding = 'utf-8') as new_file:\n",
    "            new_file.write(onestr)\n",
    "print()            \n",
    "with open('col1plus2.txt',encoding = 'utf-8') as b_file:\n",
    "    print(b_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test \n",
      " test\n"
     ]
    }
   ],
   "source": [
    "print('test \\n test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "高知県\t江川崎\n",
      "埼玉県\t熊谷\n",
      "岐阜県\t多治見\n",
      "山形県\t山形\n",
      "山梨県\t甲府\n",
      "和歌山県\tかつらぎ\n",
      "静岡県\t天竜\n",
      "山梨県\t勝沼\n",
      "埼玉県\t越谷\n",
      "群馬県\t館林\n",
      "群馬県\t上里見\n",
      "愛知県\t愛西\n",
      "千葉県\t牛久\n",
      "静岡県\t佐久間\n",
      "愛媛県\t宇和島\n",
      "山形県\t酒田\n",
      "岐阜県\t美濃\n",
      "群馬県\t前橋\n",
      "千葉県\t茂原\n",
      "埼玉県\t鳩山\n",
      "大阪府\t豊中\n",
      "山梨県\t大月\n",
      "山形県\t鶴岡\n",
      "愛知県\t名古屋\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('col1plus2.txt',encoding = 'utf-8') as b_file:\n",
    "    print(b_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "高知県\t江川崎\t41\t2013-08-12\n",
      "埼玉県\t熊谷\t40.9\t2007-08-16\n",
      "岐阜県\t多治見\t40.9\t2007-08-16\n",
      "山形県\t山形\t40.8\t1933-07-25\n",
      "山梨県\t甲府\t40.7\t2013-08-10\n"
     ]
    }
   ],
   "source": [
    "#014\n",
    "n = int(input())\n",
    "with open('hightemp.txt', encoding = 'utf-8') as a_file:\n",
    "    counter = 0\n",
    "    for line in a_file:\n",
    "        print(line.strip())\n",
    "        counter+=1\n",
    "        if counter >=n:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['埼玉県\\t鳩山\\t39.9\\t1997-07-05\\n', '大阪府\\t豊中\\t39.9\\t1994-08-08\\n', '山梨県\\t大月\\t39.9\\t1990-07-19\\n', '山形県\\t鶴岡\\t39.9\\t1978-08-03\\n', '愛知県\\t名古屋\\t39.9\\t1942-08-02\\n']\n",
      "埼玉県\t鳩山\t39.9\t1997-07-05\n",
      "大阪府\t豊中\t39.9\t1994-08-08\n",
      "山梨県\t大月\t39.9\t1990-07-19\n",
      "山形県\t鶴岡\t39.9\t1978-08-03\n",
      "愛知県\t名古屋\t39.9\t1942-08-02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#015\n",
    "n015 = int(input())\n",
    "with open('hightemp.txt', encoding = 'utf-8') as a_file:\n",
    "    count015 = 0\n",
    "    templist = []\n",
    "    for line in a_file:\n",
    "        templist.append(line)\n",
    "    newlist = []\n",
    "    for i in range(n015):\n",
    "        newlist.append(str(templist[-i-1]) )\n",
    "    nnlist = list(reversed(newlist))\n",
    "    print(nnlist)\n",
    "    \n",
    "    with open('hightemp_015.txt', mode = 'w', encoding = 'utf-8') as nf:\n",
    "        nf.write(\"\")\n",
    "        \n",
    "    with open('hightemp_015.txt', mode = 'a', encoding = 'utf-8') as nnf:\n",
    "        for i in range(len(nnlist)):\n",
    "            nnf.write(nnlist[i])\n",
    "            \n",
    "with open('hightemp_015.txt', encoding='utf-8') as a_file:\n",
    "    print(a_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "\n",
      "[['高知県', '江川崎', '41', '2013-08-12']]\n",
      "[['埼玉県', '熊谷', '40.9', '2007-08-16']]\n",
      "[['岐阜県', '多治見', '40.9', '2007-08-16']]\n",
      "[['山形県', '山形', '40.8', '1933-07-25']]\n",
      "[['山梨県', '甲府', '40.7', '2013-08-10']]\n",
      "[['和歌山県', 'かつらぎ', '40.6', '1994-08-08']]\n",
      "[['静岡県', '天竜', '40.6', '1994-08-04']]\n",
      "[['山梨県', '勝沼', '40.5', '2013-08-10']]\n",
      "[['埼玉県', '越谷', '40.4', '2007-08-16']]\n",
      "[['群馬県', '館林', '40.3', '2007-08-16']]\n",
      "[['群馬県', '上里見', '40.3', '1998-07-04']]\n",
      "[['愛知県', '愛西', '40.3', '1994-08-05']]\n",
      "[['千葉県', '牛久', '40.2', '2004-07-20'], ['静岡県', '佐久間', '40.2', '2001-07-24'], ['愛媛県', '宇和島', '40.2', '1927-07-22'], ['山形県', '酒田', '40.1', '1978-08-03'], ['岐阜県', '美濃', '40', '2007-08-16'], ['群馬県', '前橋', '40', '2001-07-24'], ['千葉県', '茂原', '39.9', '2013-08-11'], ['埼玉県', '鳩山', '39.9', '1997-07-05'], ['大阪府', '豊中', '39.9', '1994-08-08'], ['山梨県', '大月', '39.9', '1990-07-19'], ['山形県', '鶴岡', '39.9', '1978-08-03'], ['愛知県', '名古屋', '39.9', '1942-08-02']]\n"
     ]
    }
   ],
   "source": [
    "#016\n",
    "import math as m\n",
    "n016 = int(input())\n",
    "#入力には1,2,3,4,6,8,12,24を想定\n",
    "#あまりがある場合は　//、%でなんとかして\n",
    "\n",
    "\n",
    "ans = []\n",
    "with open('hightemp.txt',encoding = 'utf-8') as a_file:\n",
    "    tempfile = []\n",
    "    for line in a_file:\n",
    "        tempfile.append(line.strip().split())\n",
    "    one_gyou = 24 // n016\n",
    "    \n",
    "    syuturyoku = []\n",
    "    if 24 % n016 == 0:\n",
    "        for i in range(n016):\n",
    "            oneg = []\n",
    "            for j in range(one_gyou):\n",
    "                oneg.append(tempfile[0])\n",
    "                tempfile.remove(tempfile[0])\n",
    "            syuturyoku.append(oneg)\n",
    "        ans = syuturyoku\n",
    "    else:\n",
    "        one_gyou = m.floor(24 /n016 )\n",
    "        for i in range(n016 -1):\n",
    "            oneg = []\n",
    "            for j in range(one_gyou):\n",
    "                oneg.append(tempfile[0])\n",
    "                tempfile.remove(tempfile[0])\n",
    "            syuturyoku.append(oneg)\n",
    "        ol = []\n",
    "        for k in range(len(tempfile)):\n",
    "            ol.append(tempfile[k])\n",
    "        syuturyoku.append(ol)\n",
    "        ans = syuturyoku\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "for i in range(len(ans)):\n",
    "    print(ans[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "\n",
      "[['高知県', '江川崎', '41', '2013-08-12'], ['埼玉県', '熊谷', '40.9', '2007-08-16'], ['岐阜県', '多治見', '40.9', '2007-08-16'], ['山形県', '山形', '40.8', '1933-07-25']]\n",
      "[['山梨県', '甲府', '40.7', '2013-08-10'], ['和歌山県', 'かつらぎ', '40.6', '1994-08-08'], ['静岡県', '天竜', '40.6', '1994-08-04'], ['山梨県', '勝沼', '40.5', '2013-08-10']]\n",
      "[['埼玉県', '越谷', '40.4', '2007-08-16'], ['群馬県', '館林', '40.3', '2007-08-16'], ['群馬県', '上里見', '40.3', '1998-07-04'], ['愛知県', '愛西', '40.3', '1994-08-05']]\n",
      "[['千葉県', '牛久', '40.2', '2004-07-20'], ['静岡県', '佐久間', '40.2', '2001-07-24'], ['愛媛県', '宇和島', '40.2', '1927-07-22'], ['山形県', '酒田', '40.1', '1978-08-03']]\n",
      "[['岐阜県', '美濃', '40', '2007-08-16'], ['群馬県', '前橋', '40', '2001-07-24'], ['千葉県', '茂原', '39.9', '2013-08-11'], ['埼玉県', '鳩山', '39.9', '1997-07-05']]\n"
     ]
    }
   ],
   "source": [
    "#016\n",
    "n016 = int(input())\n",
    "#入力には1~24\n",
    "one_l = 24 // n016\n",
    "\n",
    "ans = []\n",
    "with open('hightemp.txt',encoding = 'utf-8') as a_file:\n",
    "    tempfile = []\n",
    "    for line in a_file:\n",
    "        tempfile.append(line.strip().split())\n",
    "    one_gyou = 24 // n016\n",
    "    \n",
    "    syuturyoku = []\n",
    "    for i in range(n016):\n",
    "        oneg = []\n",
    "        for j in range(one_gyou):\n",
    "            oneg.append(tempfile[0])\n",
    "            tempfile.remove(tempfile[0])\n",
    "        syuturyoku.append(oneg)\n",
    "    ans = syuturyoku\n",
    "\n",
    "\n",
    "print()\n",
    "for i in range(len(ans)):\n",
    "    print(ans[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['高', '知', '県', '埼', '玉', '県', '岐', '阜', '県', '山', '形', '県', '山', '梨', '県', '和', '歌', '山', '県', '静', '岡', '県', '山', '梨', '県', '埼', '玉', '県', '群', '馬', '県', '群', '馬', '県', '愛', '知', '県', '千', '葉', '県', '静', '岡', '県', '愛', '媛', '県', '山', '形', '県', '岐', '阜', '県', '群', '馬', '県', '千', '葉', '県', '埼', '玉', '県', '大', '阪', '府', '山', '梨', '県', '山', '形', '県', '愛', '知', '県']\n",
      "['大', '馬', '知', '葉', '県', '静', '愛', '形', '高', '埼', '岡', '岐', '府', '媛', '群', '玉', '阪', '歌', '和', '山', '梨', '阜', '千']\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "#017\n",
    "with open('hightemp.txt', encoding = 'utf-8') as a_file:\n",
    "    \n",
    "    f = a_file.readlines()\n",
    "    gl =[]\n",
    "    for i in range(len(f)):\n",
    "        g = list(f[i].split())\n",
    "        sl = list(g[0])\n",
    "        for i in range(len(sl)):\n",
    "            gl.append(sl[i])\n",
    "    print(gl)\n",
    "    print(list(set(gl)))\n",
    "    print(len(list(set(gl))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['愛媛県', '宇和島', '40.2', '1927-07-22'], ['山形県', '山形', '40.8', '1933-07-25'], ['愛知県', '名古屋', '39.9', '1942-08-02'], ['山形県', '酒田', '40.1', '1978-08-03'], ['山形県', '鶴岡', '39.9', '1978-08-03'], ['山梨県', '大月', '39.9', '1990-07-19'], ['静岡県', '天竜', '40.6', '1994-08-04'], ['愛知県', '愛西', '40.3', '1994-08-05'], ['和歌山県', 'かつらぎ', '40.6', '1994-08-08'], ['大阪府', '豊中', '39.9', '1994-08-08'], ['埼玉県', '鳩山', '39.9', '1997-07-05'], ['群馬県', '上里見', '40.3', '1998-07-04'], ['静岡県', '佐久間', '40.2', '2001-07-24'], ['群馬県', '前橋', '40', '2001-07-24'], ['千葉県', '牛久', '40.2', '2004-07-20'], ['埼玉県', '熊谷', '40.9', '2007-08-16'], ['岐阜県', '多治見', '40.9', '2007-08-16'], ['埼玉県', '越谷', '40.4', '2007-08-16'], ['群馬県', '館林', '40.3', '2007-08-16'], ['岐阜県', '美濃', '40', '2007-08-16'], ['山梨県', '甲府', '40.7', '2013-08-10'], ['山梨県', '勝沼', '40.5', '2013-08-10'], ['千葉県', '茂原', '39.9', '2013-08-11'], ['高知県', '江川崎', '41', '2013-08-12']]\n"
     ]
    }
   ],
   "source": [
    "#018\n",
    "with open('hightemp.txt', encoding = 'utf-8') as ab_file:\n",
    "    rl = ab_file.readlines()\n",
    "    nl = []\n",
    "    for i in range(len(rl)):\n",
    "        onel = list(rl[i].split())\n",
    "        nl.append(onel)\n",
    "    sort_data = sorted(nl,key=lambda x: x[3])\n",
    "    #print(nl)\n",
    "    print(sort_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#020\n",
    "import gzip\n",
    "import json\n",
    "from io import StringIO\n",
    "\n",
    "with gzip.open('jawiki-country.json.gz', \"rt\") as a_file:\n",
    "    for line in a_file:\n",
    "        jdata = json.load(StringIO(line))\n",
    "        if jdata['title'] == 'イギリス':\n",
    "            data = jdata['text']\n",
    "            print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'山': 6, '埼': 3, '群': 3, '愛': 3, '岐': 2, '静': 2, '千': 2, '高': 1, '和': 1, '大': 1}\n"
     ]
    }
   ],
   "source": [
    "#019\n",
    "with open('hightemp.txt', encoding = 'utf-8') as ab_file:\n",
    "    rl = ab_file.readlines()\n",
    "    nl = []\n",
    "    for i in range(len(rl)):\n",
    "        onel = list(rl[i].split())\n",
    "        nl.append(onel)\n",
    "    kend = {}\n",
    "    for j in range(len(nl)):\n",
    "        if rl[j][0] in kend:\n",
    "            kend[rl[j][0]] = kend[rl[j][0]] + 1\n",
    "        else:\n",
    "            kend.update({rl[j][0] : 1})\n",
    "    s = dict(sorted(kend.items(), key=lambda x:x[1], reverse = True))\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'高': 1, '埼': 3, '岐': 2, '山': 6, '和': 1, '静': 2, '群': 3, '愛': 3, '千': 2, '大': 1}\n",
      "{'山': 6, '埼': 3, '群': 3, '愛': 3, '岐': 2, '静': 2, '千': 2, '高': 1, '和': 1, '大': 1}\n"
     ]
    }
   ],
   "source": [
    "#019\n",
    "with open('hightemp.txt', encoding = 'utf-8') as ab_file:\n",
    "    rl = ab_file.readlines()\n",
    "    nl = []\n",
    "    for i in range(len(rl)):\n",
    "        onel = list(rl[i].split())\n",
    "        nl.append(onel)\n",
    "    kend = {}\n",
    "    for j in range(len(nl)):\n",
    "        if rl[j][0] in kend:\n",
    "            kend[rl[j][0]] = kend[rl[j][0]] + 1\n",
    "        else:\n",
    "            kend.update({rl[j][0] : 1})\n",
    "    print(kend)\n",
    "    s = dict(sorted(kend.items(), key=lambda x:x[1], reverse = True))\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding utf-8\n",
    "import gzip\n",
    "import json\n",
    "fname = 'jawiki-country.json.gz'\n",
    "\n",
    "with gzip.open(fname,'rt') as data_file:\n",
    "    for line in data_file:\n",
    "        data_json = json.loads(line)\n",
    "        if data_json['title'] == 'イギリス':\n",
    "            print(data_json['text'])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import re\n",
    "fname = 'jawiki-country.json.gz'\n",
    "\n",
    "def extract_UK():\n",
    "    \n",
    "    with gzip.open(fname,'rt') as data_file:\n",
    "        for line in data_file:\n",
    "            data_json = json.loads(line)\n",
    "            if data_json['title'] == 'イギリス':\n",
    "                return data_json['text']\n",
    "        raise ValueError('Not found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#正規表現\n",
    "#http://s5.cocolog-nifty.com/blog/gpc-regular-expressions-j.html\n",
    "#match =re.search(pattern,str)\n",
    "str_ex = \"an example word:cat!!\"\n",
    "match = re.search(r'word:\\w\\w\\w', str_ex)\n",
    "if match:\n",
    "    print('yes')\n",
    "else:\n",
    "    print('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(str_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_ex2 = \"Joke: what do you call a pig with three eyes? piiig!\"\n",
    "match = re.search(r'iii',str_ex2)\n",
    "match2 = re.search(r'igs', str_ex2)\n",
    "print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match3 = re.search(r'..g',str_ex2)\n",
    "print(match3.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match = re.search(r'pi+', 'piiiig')\n",
    "print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match4 = re.search(r'\\w\\w\\w+', '@@abcd!!')\n",
    "print(match4.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match = re.search(r'i+', 'piigiiii')\n",
    "print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#021\n",
    "uk = [extract_UK()]\n",
    "category = re.compile(r'\\[\\[Category\\:.*\\]\\]')\n",
    "for line in uk:\n",
    "    if category.match(line):\n",
    "        print(line.strip())\n",
    "import re\n",
    "#print(data)\n",
    "data_list = data.strip().split(\"\\n\")\n",
    "category = re.compile(r'\\[\\[Category\\:.*\\]\\]')\n",
    "for line in data_list:\n",
    "    if category.match(line):\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# re practice cf. http://s5.cocolog-nifty.com/blog/gpc-regular-expressions-j.html\n",
    "\n",
    "match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx1 2  34cc')\n",
    "print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match = re.search(r'^b\\w+','foobar')\n",
    "print(match)\n",
    "match = re.search(r'b\\w+','fooobaaaar')\n",
    "print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#023\n",
    "import gzip\n",
    "import json\n",
    "import re\n",
    "fname = 'jawiki-country.json.gz'\n",
    "\n",
    "rules = re.compile(r'(==\\w+==)|(===\\w+===)|(====\\w+====)')\n",
    "\n",
    "data_list = data.strip().split(\"\\n\")\n",
    "for line in data_list:\n",
    "    if rules.match(line):\n",
    "        result = rules.search(line)\n",
    "        \n",
    "        if result.group(1):\n",
    "            print(result.group(1)[2:-2],1)\n",
    "        elif result.group(2):\n",
    "            print(result.group(2)[3:-3],2)\n",
    "        elif result.group(3):\n",
    "            print(result.group(3)[4:-4],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#024 \n",
    "import gzip\n",
    "import json\n",
    "import re\n",
    "\n",
    "fname = 'jawiki-country.json.gz'\n",
    "\n",
    "pattern = re.compile(r'''\n",
    "    (?:File|ファイル)   # 非キャプチャ、'File'か'ファイル'\n",
    "    :\n",
    "    (.+?)   # キャプチャ対象、任意の文字1文字以上、非貪欲\n",
    "    \\|\n",
    "    ''', re.VERBOSE)\n",
    "\n",
    "result = pattern.findall(extract_UK())\n",
    "\n",
    "for line in result:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#regex practice\n",
    "\n",
    "strr = 'purple alice-b@google.com monkey dishwasher'\n",
    "match = re.search(r'\\w+@\\w+',strr)\n",
    "print(match.group())\n",
    "\n",
    "#かぎかっこ\n",
    "#[]は文字の集まりを表せる\n",
    "strr = 'purple alice-b@google.com monkey dishwasher'\n",
    "match = re.search(r'[\\w.-]+@[\\w.-]+', strr)\n",
    "print(match.group())\n",
    "\n",
    "strrr = 'purple alice-b@google.com monkey dishwasher'\n",
    "match = re.search(r'([\\w.-]+)@([\\w.-]+)',strrr)\n",
    "if match:\n",
    "    print(match.group())\n",
    "    print(match.group(1))\n",
    "    print(match.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#findall\n",
    "\n",
    "strrrr = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n",
    "\n",
    "## re.findall は見つかった電子メールの文字列を、全て返す\n",
    "emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+',strrrr)\n",
    "for email in emails:\n",
    "    print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file open\n",
    "f = open('hightemp.txt', encoding='utf-8',mode = 'r')\n",
    "allstr = re.findall(r'..県',f.read())\n",
    "print(allstr)\n",
    "f.close()\n",
    "\n",
    "strts = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n",
    "tpl = re.findall(r'([\\w\\.-]+)@([\\w\\.-]+)',strts)\n",
    "print(tpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#024 syakyo qiita\n",
    "#https://qiita.com/segavvy/items/03b97eb6a39f5ae6aa34\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "import re\n",
    "\n",
    "fname = 'jawiki-country.json.gz'\n",
    "\n",
    "pattern = re.compile(r'''\n",
    "(?:File|ファイル) # File or　ファイル\n",
    ":\n",
    "(.+?) #　. で任意の文字、 + どんどんのばす　?最小　非貪欲\n",
    "\\|\n",
    "''',re.VERBOSE)\n",
    "\n",
    "# result, findall\n",
    "result = pattern.findall(extract_UK())\n",
    "\n",
    "for line in result:\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#025\n",
    "item = data.split(r\"\\n}}\\n\")[0].split(\"\\n|\")\n",
    "\n",
    "    \n",
    "print(item_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#026\n",
    "# What is intenced markup\n",
    "#まず必要な部分を抜き出す\n",
    "\n",
    "item= data.split(r\"\\n}}\\n\")[0].split('\\n|')\n",
    "\n",
    "def cleaner(text):\n",
    "    cleaned = re.sub(r\"(\\'\\')|(\\'\\'\\')|(\\'\\'\\'\\'\\')\", \"\", text)\n",
    "    return cleaned\n",
    "\n",
    "import collections\n",
    "import math\n",
    "\n",
    "item_rule = re.compile(r'(.+)\\s\\=\\s(.+)')\n",
    "item_dic = collections.OrderedDict()\n",
    "# 通常のdictionaryだと、追加するうちに順番がバラバラになる\n",
    "for i in item:\n",
    "    match = re.search(item_rule,cleaner(i))\n",
    "    \n",
    "    if match:\n",
    "        item_dic[match.group(1)] = match.group(2)\n",
    "        \n",
    "print(item_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#027\n",
    "# http delete\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
